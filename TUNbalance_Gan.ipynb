{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TUNbalance/Gan.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPuJRa9wHIArBDL4kgOlkLq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jnsbrdbr/thesis/blob/thesis/TUNbalance_Gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TedFoYnP5Wjt",
        "outputId": "3856e274-0fe8-48be-ed96-0c988124e7b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # Colab only.`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n",
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# Install TensorFlow\n",
        "# !pip install -q tensorflow-gpu==2.0.0-rc0\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x  # Colab only.\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Input, Dense, Activation, LeakyReLU, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys, os\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "dVJbVj-27-iL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHyGZgXT8A6q",
        "outputId": "a0f08fb1-e860-4a39-cf11-579d30f858e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pickle5\n",
        "import pickle5 as pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaqFN78G8Hdv",
        "outputId": "02bdb302-c51d-427d-b63b-8160614837c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/dist-packages (0.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.HDFStore('/content/drive/MyDrive/1000/TUnsmote_result',  mode='r') as newstore:\n",
        "    result = newstore.select('result')"
      ],
      "metadata": {
        "id": "1IwapRcQ8JSH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#final data\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmuSpxOu8gll",
        "outputId": "84fc1e6f-7b35-451e-acdf-873ceea4a853"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            0         1         2  ...             8             9  label\n",
            "0   -1.715972 -3.099936 -0.041249  ... -1.071834e-02 -9.464034e-03      1\n",
            "1   -1.715972 -3.099936 -0.041249  ... -3.168693e-02 -7.296139e-03      1\n",
            "2   -1.715972 -3.099936 -0.041249  ...  7.887649e-03 -4.402416e-02      1\n",
            "3   -1.715972 -3.099936 -0.041249  ...  8.369804e-03  2.997764e-02      1\n",
            "4   -1.715972 -3.099936 -0.041249  ...  3.817151e-13  4.136409e-16      1\n",
            "..        ...       ...       ...  ...           ...           ...    ...\n",
            "995 -2.114893 -4.572474 -0.754679  ...  2.281326e-03  5.690586e-03      1\n",
            "996 -2.114893 -4.572474 -0.754679  ... -3.257351e-03 -1.247434e-02      1\n",
            "997 -2.114893 -4.572474 -0.754679  ... -1.938248e-02 -7.635838e-03      1\n",
            "998 -2.114893 -4.572474 -0.754679  ... -2.508770e-02 -7.523238e-03      1\n",
            "999 -2.114893 -4.572474 -0.754679  ... -1.098104e-02  1.125916e-03      1\n",
            "\n",
            "[1000 rows x 71 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#divide data in to data_label and non_data label\n",
        "\n",
        "import copy\n",
        "result_nonlabel=copy.deepcopy(result)\n",
        "del result_nonlabel['label']\n",
        "X=result_nonlabel\n",
        "y=result.label"
      ],
      "metadata": {
        "id": "YOs9Xc_aCj1V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting data in to test and train...\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y ,random_state=42,test_size=0.3)#"
      ],
      "metadata": {
        "id": "KDFNMGJPCz_J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('shape of x_train is:',X_train.shape)\n",
        "print('shape of x_test is:',X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFfz077yC1az",
        "outputId": "bb2e54bb-2a90-468a-929f-6abb3a4167c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of x_train is: (700, 70)\n",
            "shape of x_test is: (300, 70)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_latent_samples(n_samples, sample_size):\n",
        "    #return np.random.uniform(-1, 1, size=(n_samples, sample_size))\n",
        "    return np.random.normal(loc=0, scale=1, size=(n_samples, sample_size))"
      ],
      "metadata": {
        "id": "1F0ZTSg7C3hA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_latent_samples(1, 300) # generates one sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQyJU64cC44_",
        "outputId": "7426aa4b-5286-4e1e-bcf1-6c369a5fcc59"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.49823750e+00,  7.22429572e-01, -3.60917986e-01,\n",
              "        -2.91323317e-01,  5.59640133e-01, -5.14243056e-01,\n",
              "         6.49092721e-01, -1.89695217e+00,  7.23751164e-01,\n",
              "         5.67027468e-01, -1.08555078e+00, -5.97402363e-01,\n",
              "         6.01369786e-01,  5.18162778e-01,  1.76531447e+00,\n",
              "         1.05491528e-01,  1.31613117e+00,  2.16851655e-01,\n",
              "        -1.66942271e-01, -1.14968739e+00, -1.05574779e+00,\n",
              "         1.61189049e+00, -1.44760281e-01,  1.12197860e+00,\n",
              "        -2.35651674e-02, -7.49966372e-01, -3.72494159e-01,\n",
              "         1.55878609e-01, -6.22258993e-01,  1.24739106e+00,\n",
              "        -1.74005816e-01,  4.54142619e-01, -2.85171655e-01,\n",
              "         6.94516447e-01,  8.60891940e-01,  3.96029973e-01,\n",
              "         2.70072193e-01,  5.79524425e-02, -3.13822411e-01,\n",
              "        -1.11599597e+00,  5.12396319e-01, -6.74550187e-01,\n",
              "        -5.65188321e-01,  1.06518530e+00,  1.82161644e+00,\n",
              "         1.05832095e+00, -1.85052990e+00,  8.57928104e-01,\n",
              "         4.40248856e-01, -4.27466064e-01,  9.28430262e-01,\n",
              "        -5.76133376e-01, -1.67311085e+00,  5.29123317e-01,\n",
              "         5.22711392e-01,  1.62452942e+00, -1.83904424e-01,\n",
              "         2.47595414e-01,  7.44729238e-01,  1.15619247e+00,\n",
              "         4.95568294e-01, -4.98518476e-01, -4.67555566e-01,\n",
              "        -7.75106866e-01, -5.39330275e-01, -1.06965687e+00,\n",
              "        -5.15878181e-01, -1.49693885e+00, -3.92931887e-01,\n",
              "         8.53124065e-01, -6.46629376e-02, -1.97296774e-01,\n",
              "        -2.01036821e+00,  2.24439183e-01, -5.95998084e-01,\n",
              "        -4.70241742e-01,  3.55862592e-01, -9.02615993e-01,\n",
              "         2.37594232e-01,  1.39546148e+00, -8.29231099e-01,\n",
              "         2.51913380e+00,  8.40041061e-01,  8.50630599e-01,\n",
              "        -4.65464333e-01, -8.11189455e-01,  1.15251009e+00,\n",
              "        -1.98729598e-01, -1.78817762e+00,  8.54876895e-01,\n",
              "        -7.13133915e-01, -1.39683872e+00, -1.65041164e-01,\n",
              "         1.99270465e+00,  7.11991074e-01,  1.78535154e-01,\n",
              "        -9.28677873e-02, -1.00151356e+00,  6.04751972e-02,\n",
              "         1.55010115e+00,  3.75801914e-02, -1.51866891e+00,\n",
              "         7.16603526e-01, -1.34577803e-01,  1.19981145e+00,\n",
              "        -9.94658057e-01, -1.18287196e-01, -2.65811888e-01,\n",
              "         1.24115638e+00, -1.44544270e-01, -4.11611765e-01,\n",
              "        -7.71405892e-03,  2.65026306e+00,  7.17334617e-01,\n",
              "         6.26493369e-01, -6.72303180e-01, -7.56796367e-01,\n",
              "        -3.20951252e-02, -3.09466492e-01, -5.90787273e-01,\n",
              "        -8.24194265e-01,  5.63373872e-01,  5.07449524e-01,\n",
              "        -2.17999689e-01,  6.24819241e-01, -9.98811323e-02,\n",
              "         1.08565205e+00,  3.22787160e-01,  9.54467630e-01,\n",
              "        -7.21425044e-02,  7.66148764e-01, -1.91030830e+00,\n",
              "         6.88378717e-01, -6.51283737e-01, -9.43232786e-01,\n",
              "         1.97928917e+00, -6.91090738e-01, -1.22334643e+00,\n",
              "        -1.05614746e+00,  9.09008266e-01, -1.84505331e+00,\n",
              "        -1.05307356e+00, -1.96529626e-01,  5.92434004e-01,\n",
              "         7.02676683e-01, -1.75378009e+00, -5.18213798e-01,\n",
              "         3.93549621e-01,  2.22753476e-01,  2.50054782e-01,\n",
              "         2.38115426e+00, -9.37006918e-01, -1.18197051e+00,\n",
              "         5.42573571e-01, -1.55418588e+00,  2.14128759e-01,\n",
              "        -9.73602190e-01, -1.22597877e+00, -2.00108695e-01,\n",
              "        -7.21957669e-01,  3.50591996e-01, -3.95109872e-01,\n",
              "        -5.18199114e-01, -1.29014422e-01, -1.18605992e+00,\n",
              "        -1.82292219e+00,  1.03025093e+00, -4.61387647e-01,\n",
              "         1.25159467e+00,  1.50561152e+00, -1.99360691e+00,\n",
              "         1.95887544e-01, -1.38838090e-01, -2.52643606e-01,\n",
              "         3.84360955e-01, -1.65579287e+00, -2.71272580e+00,\n",
              "        -1.13160057e+00, -1.43400476e+00,  1.01703922e+00,\n",
              "        -1.41076605e+00, -2.19176615e-01,  3.58261913e-01,\n",
              "         5.48729962e-01,  9.16384844e-01, -1.92349100e-01,\n",
              "         1.24376037e+00,  1.10716297e+00, -1.34724690e+00,\n",
              "        -1.30270474e+00, -3.88782126e-02,  1.30803706e+00,\n",
              "        -1.30123540e-01,  8.33923617e-02,  2.95256863e+00,\n",
              "         2.14636922e-01, -1.53784392e-01, -4.07173587e-01,\n",
              "         3.16733723e-01, -1.50856196e+00,  9.26198741e-02,\n",
              "         1.17323831e+00, -4.34796043e-01, -3.40383074e-01,\n",
              "        -2.79062538e+00,  2.38315545e-01, -1.91735435e+00,\n",
              "        -6.27217036e-01, -9.25162366e-01, -5.96761468e-01,\n",
              "        -4.40069099e-01, -4.49359939e-01, -3.98742716e-01,\n",
              "         2.50147357e-01, -2.47966718e+00,  5.95243126e-01,\n",
              "         1.49838702e-02, -1.21497461e+00,  4.22758779e-01,\n",
              "         3.15697389e-01, -2.28640877e-01, -1.43169428e+00,\n",
              "         1.42219505e+00, -9.08612170e-01,  1.08539186e+00,\n",
              "        -1.13919132e+00,  1.75554147e+00,  9.40368382e-01,\n",
              "         4.95824730e-01, -8.25377327e-01,  9.54132409e-02,\n",
              "        -1.43961142e+00, -6.31169532e-01, -5.93042215e-01,\n",
              "        -1.63663924e+00,  6.11262056e-01,  1.59557673e-01,\n",
              "        -5.39667824e-01,  8.51509884e-01, -7.73865978e-01,\n",
              "        -1.29916469e+00, -3.23386742e+00, -3.00720860e-01,\n",
              "        -5.54532493e-02, -6.94697959e-01,  1.15846677e+00,\n",
              "        -7.35616175e-01,  8.21663759e-01,  4.28000847e-02,\n",
              "         7.94558985e-01,  7.39014285e-01, -2.37636527e-01,\n",
              "         2.05203778e+00,  1.95480737e-04, -3.83663791e-01,\n",
              "         5.62583254e-01,  1.47145932e+00,  2.47614187e-01,\n",
              "         1.80766910e-01, -1.44042498e+00,  2.41871882e+00,\n",
              "        -6.42090110e-01,  1.40444597e+00,  5.14074983e-01,\n",
              "         4.02740093e-01,  1.33613349e+00, -8.50605867e-01,\n",
              "        -1.95775054e-01,  6.11924036e-01, -6.81755065e-01,\n",
              "        -9.93628794e-01,  6.19771320e-01,  1.06668889e+00,\n",
              "         1.86445059e-01, -1.77530068e+00,  1.55984720e-01,\n",
              "        -3.13445864e-01, -5.41933731e-01, -2.50310214e-01,\n",
              "         1.49444023e-01,  4.48818195e-01,  5.86347410e-01,\n",
              "        -1.79414369e+00, -7.48454978e-01,  1.34960134e+00,\n",
              "        -1.34387063e+00, -1.33371353e-01,  9.43179313e-01,\n",
              "        -1.99878449e+00,  8.60847418e-01,  9.25918093e-01,\n",
              "        -7.86018347e-01,  1.33921838e-01, -5.61938933e-01,\n",
              "         7.00348486e-01,  1.87739453e-01, -1.97469534e+00,\n",
              "         7.70815728e-01,  2.69403423e+00,  1.22021954e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Sequential([\n",
        "    Dense(256, input_shape=(100,)),\n",
        "    LeakyReLU(alpha=0.02),\n",
        "    #BatchNormalization(momentum=0.6),\n",
        "    #Dense(512),\n",
        "    #LeakyReLU(alpha=0.02),\n",
        "    #BatchNormalization(momentum=0.6),\n",
        "    #Dense(256),\n",
        "    #LeakyReLU(alpha=0.02),\n",
        "    #BatchNormalization(momentum=0.6),\n",
        "    #Dense(128),\n",
        "    #LeakyReLU(alpha=0.02),\n",
        "    #BatchNormalization(momentum=0.6),\n",
        "    Dense(70),\n",
        "    Activation('tanh')\n",
        "], name='generator')\n",
        "\n",
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MedUL6ngC72k",
        "outputId": "42c01ebc-63f4-4066-dd45-a33b63dc4d55"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 70)                17990     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 70)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,846\n",
            "Trainable params: 43,846\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = Sequential([\n",
        "    Dense(128, input_shape=(70,)),\n",
        "    LeakyReLU(alpha=0.02),\n",
        "    #(momentum=0.6),\n",
        "    Dense(64),\n",
        "    LeakyReLU(alpha=0.02),\n",
        "    #BatchNormalization(momentum=0.6),\n",
        "    Dense(32),\n",
        "    LeakyReLU(alpha=0.02),\n",
        "    #BatchNormalization(momentum=0.6),\n",
        "    #Dense(16),\n",
        "    #LeakyReLU(alpha=0.02),\n",
        "    #BatchNormalization(momentum=0.6),\n",
        "    #Dense(8),\n",
        "    #LeakyReLU(alpha=0.02),\n",
        "    #BatchNormalization(momentum=0.6),\n",
        "    Dense(1),\n",
        "    Activation('sigmoid')\n",
        "], name='discriminator')\n",
        "\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ_AFOBWC9DM",
        "outputId": "382b1bb8-d9a7-4607-c43d-e8c143f7d610"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 128)               9088      \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,457\n",
            "Trainable params: 19,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# maintain the same shared weights with the generator and the discriminator.\n",
        "gan = Sequential([\n",
        "    generator,\n",
        "    discriminator\n",
        "])\n",
        "\n",
        "gan.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzpglarWDA5p",
        "outputId": "35976149-b46b-4920-d009-bf569afb29b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " generator (Sequential)      (None, 70)                43846     \n",
            "                                                                 \n",
            " discriminator (Sequential)  (None, 1)                 19457     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 63,303\n",
            "Trainable params: 63,303\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_trainable(model, trainable):\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = trainable"
      ],
      "metadata": {
        "id": "jcQFa2llDDb9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_trainable(discriminator, False)\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmNw2ufIDEuQ",
        "outputId": "3fcbd0e6-b161-4dba-ec04-2e31691503ce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 128)               9088      \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,457\n",
            "Trainable params: 0\n",
            "Non-trainable params: 19,457\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_trainable(discriminator, True)\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTgogN-IDGjL",
        "outputId": "c6ccb7e1-59f2-4a05-9bf7-949b2edd9ef4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 128)               9088      \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,457\n",
            "Trainable params: 19,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_simple_GAN(sample_size, \n",
        "                    g_hidden_size_1,\n",
        "                    g_hidden_size_2,\n",
        "                    g_hidden_size_3,\n",
        "                    g_hidden_size_4,\n",
        "                    d_hidden_size_1,\n",
        "                    d_hidden_size_2, \n",
        "                    d_hidden_size_3,\n",
        "                    d_hidden_size_4,\n",
        "                    d_hidden_size_5,\n",
        "                    leaky_alpha, \n",
        "                    g_learning_rate,\n",
        "                    d_learning_rate):\n",
        "    K.clear_session()\n",
        "    \n",
        "    generator = Sequential([\n",
        "        Dense(g_hidden_size_1, input_shape=(sample_size,)),\n",
        "        LeakyReLU(alpha=leaky_alpha),\n",
        "        #BatchNormalization(momentum=0.6),\n",
        "        #Dense(g_hidden_size_2),\n",
        "        #LeakyReLU(alpha=leaky_alpha),\n",
        "        #BatchNormalization(momentum=0.6),\n",
        "        #Dense(g_hidden_size_3),\n",
        "        #LeakyReLU(alpha=leaky_alpha),\n",
        "        #BatchNormalization(momentum=0.6),\n",
        "        #Dense(g_hidden_size_4),\n",
        "        #LeakyReLU(alpha=leaky_alpha),\n",
        "        #BatchNormalization(momentum=0.6),\n",
        "        Dense(70),        \n",
        "        Activation('tanh')\n",
        "    ], name='generator')    \n",
        "\n",
        "    discriminator = Sequential([\n",
        "        Dense(d_hidden_size_1, input_shape=(70,)),\n",
        "        LeakyReLU(alpha=leaky_alpha),\n",
        "        #BatchNormalization(momentum=0.6),\n",
        "        Dense(d_hidden_size_2),\n",
        "        LeakyReLU(alpha=leaky_alpha),\n",
        "        #BatchNormalization(momentum=0.6),\n",
        "        Dense(d_hidden_size_3),\n",
        "        LeakyReLU(alpha=leaky_alpha),\n",
        "        #BatchNormalization(momentum=0.6),\n",
        "        #Dense(d_hidden_size_4),\n",
        "        #LeakyReLU(alpha=leaky_alpha),\n",
        "        #BatchNormalization(momentum=0.6),\n",
        "        #Dense(d_hidden_size_5),\n",
        "        #LeakyReLU(alpha=leaky_alpha),\n",
        "        #BatchNormalization(momentum=0.6),\n",
        "        Dense(1),\n",
        "        Activation('sigmoid')\n",
        "    ], name='discriminator')    \n",
        "    \n",
        "    gan = Sequential([\n",
        "        generator,\n",
        "        discriminator\n",
        "    ])\n",
        "    \n",
        "    discriminator.compile(optimizer=Adam(lr=d_learning_rate), loss='binary_crossentropy')\n",
        "    gan.compile(optimizer=Adam(lr=g_learning_rate), loss='binary_crossentropy')\n",
        "    \n",
        "    return gan, generator, discriminator "
      ],
      "metadata": {
        "id": "Y1NR5ScFDINq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "def preprocess(x):\n",
        "   x = preprocessing.scale(x)\n",
        "   return x"
      ],
      "metadata": {
        "id": "pTB_Cw2xDMgm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_real = np.array(preprocess(X_train))\n",
        "X_test_real  = np.array(preprocess(X_test))"
      ],
      "metadata": {
        "id": "Ip_EsmkHDNjL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_labels(size):\n",
        "    return np.ones([size, 1]), np.zeros([size, 1])"
      ],
      "metadata": {
        "id": "rH90M0ypDT64"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_real_10, y_fake_10 = make_labels(10)\n",
        "\n",
        "y_real_10, y_fake_10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAMwQybFDVQq",
        "outputId": "013b2d40-c9ec-4351-9359-27b356f0a198"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.]]), array([[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "sample_size     = 100     # latent sample size (i.e., 100 random numbers)\n",
        "g_hidden_size_1 = 256\n",
        "g_hidden_size_2 = 0\n",
        "g_hidden_size_3 = 0\n",
        "g_hidden_size_4 = 0\n",
        "d_hidden_size_1 = 128\n",
        "d_hidden_size_2 = 64\n",
        "d_hidden_size_3 = 32\n",
        "d_hidden_size_4 = 16\n",
        "d_hidden_size_5 = 8\n",
        "leaky_alpha     = 0.02\n",
        "g_learning_rate = 0.0001  # learning rate for the generator\n",
        "d_learning_rate = 0.001   # learning rate for the discriminator\n",
        "epochs          = 200\n",
        "batch_size      = 64      # train batch size\n",
        "eval_size       = 16      # evaluate size\n",
        "smooth          = 0.1\n"
      ],
      "metadata": {
        "id": "zjBaUGf2DVoP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## labels for the batch size and the test size\n",
        "y_train_real, y_train_fake = make_labels(batch_size)\n",
        "y_eval_real,  y_eval_fake  = make_labels(eval_size)\n",
        "\n",
        "# create a GAN, a generator and a discriminator\n",
        "gan, generator, discriminator = make_simple_GAN(\n",
        "    sample_size, \n",
        "    g_hidden_size_1, \n",
        "    g_hidden_size_2,\n",
        "    g_hidden_size_3,\n",
        "    g_hidden_size_4, \n",
        "    d_hidden_size_1, \n",
        "    d_hidden_size_2,\n",
        "    d_hidden_size_3,\n",
        "    d_hidden_size_4,\n",
        "    d_hidden_size_5,\n",
        "    leaky_alpha, \n",
        "    g_learning_rate,\n",
        "    d_learning_rate)\n",
        "\n",
        "\n",
        "losses = []\n",
        "losses1 = []\n",
        "for e in range(epochs):\n",
        "    for i in range(len(X_train_real)//batch_size):\n",
        "        # real MNIST digit images\n",
        "        X_batch_real = X_train_real[i*batch_size:(i+1)*batch_size]\n",
        "        \n",
        "        # latent samples and the generated digit images\n",
        "        latent_samples = make_latent_samples(batch_size, sample_size)\n",
        "        X_batch_fake = generator.predict_on_batch(latent_samples)\n",
        "        \n",
        "        # train the discriminator to detect real and fake images\n",
        "        make_trainable(discriminator, True)\n",
        "        discriminator.train_on_batch(X_batch_real, y_train_real * (1 - smooth))\n",
        "        discriminator.train_on_batch(X_batch_fake, y_train_fake)\n",
        "\n",
        "        # train the generator via GAN\n",
        "        make_trainable(discriminator, False)\n",
        "        gan.train_on_batch(latent_samples, y_train_real)\n",
        "   # evaluate\n",
        "    X_eval_real = X_test_real[np.random.choice(len(X_test_real), eval_size, replace=False)]\n",
        "    \n",
        "    latent_samples = make_latent_samples(eval_size, sample_size)\n",
        "    X_eval_fake = generator.predict_on_batch(latent_samples)\n",
        "\n",
        "    d_loss  = discriminator.test_on_batch(X_eval_real, y_eval_real)\n",
        "    d_loss += discriminator.test_on_batch(X_eval_fake, y_eval_fake)\n",
        "    g_loss  = gan.test_on_batch(latent_samples, y_eval_real) # we want the fake to be realistic!\n",
        "    \n",
        "    losses.append((d_loss, g_loss))\n",
        "\n",
        "    #d_acc_real = discriminator.train_on_batch(X_batch_real, y_train_real * (1 - smooth))\n",
        "    #d_acc_fake = discriminator.train_on_batch(X_batch_fake, y_train_fake)\n",
        "    #d_acc  = 0.5 * (d_acc_real + d_acc_fake)\n",
        "\n",
        "    #losses1.append(( d_acc))\n",
        "    print(\"Epoch: {:>3}/{} Discriminator Loss: {:>6.4f} Generator Loss: {:>6.4f} \".format(\n",
        "        e+1, epochs, d_loss, g_loss)) #Discriminator acc: {:>6.4f}:,d_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2gEPAnODX5R",
        "outputId": "48ffc8f8-eed0-4514-bcfd-6bb782b0d450"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   1/200 Discriminator Loss: 0.8995 Generator Loss: 0.7917 \n",
            "Epoch:   2/200 Discriminator Loss: 0.5109 Generator Loss: 1.2248 \n",
            "Epoch:   3/200 Discriminator Loss: 0.2794 Generator Loss: 1.9950 \n",
            "Epoch:   4/200 Discriminator Loss: 0.3593 Generator Loss: 2.0901 \n",
            "Epoch:   5/200 Discriminator Loss: 0.2499 Generator Loss: 2.1286 \n",
            "Epoch:   6/200 Discriminator Loss: 0.3260 Generator Loss: 2.1271 \n",
            "Epoch:   7/200 Discriminator Loss: 0.3235 Generator Loss: 2.5144 \n",
            "Epoch:   8/200 Discriminator Loss: 0.2409 Generator Loss: 2.6873 \n",
            "Epoch:   9/200 Discriminator Loss: 0.2045 Generator Loss: 2.6904 \n",
            "Epoch:  10/200 Discriminator Loss: 0.1507 Generator Loss: 3.5253 \n",
            "Epoch:  11/200 Discriminator Loss: 0.1559 Generator Loss: 3.8472 \n",
            "Epoch:  12/200 Discriminator Loss: 0.1945 Generator Loss: 3.7882 \n",
            "Epoch:  13/200 Discriminator Loss: 0.7057 Generator Loss: 4.0555 \n",
            "Epoch:  14/200 Discriminator Loss: 0.2049 Generator Loss: 4.4470 \n",
            "Epoch:  15/200 Discriminator Loss: 0.1441 Generator Loss: 4.4269 \n",
            "Epoch:  16/200 Discriminator Loss: 0.1330 Generator Loss: 4.8216 \n",
            "Epoch:  17/200 Discriminator Loss: 0.2012 Generator Loss: 4.8642 \n",
            "Epoch:  18/200 Discriminator Loss: 0.1711 Generator Loss: 4.5546 \n",
            "Epoch:  19/200 Discriminator Loss: 0.2261 Generator Loss: 4.8249 \n",
            "Epoch:  20/200 Discriminator Loss: 0.1966 Generator Loss: 5.4040 \n",
            "Epoch:  21/200 Discriminator Loss: 0.2112 Generator Loss: 5.2100 \n",
            "Epoch:  22/200 Discriminator Loss: 0.2253 Generator Loss: 4.9081 \n",
            "Epoch:  23/200 Discriminator Loss: 0.2175 Generator Loss: 5.3059 \n",
            "Epoch:  24/200 Discriminator Loss: 0.1554 Generator Loss: 4.8475 \n",
            "Epoch:  25/200 Discriminator Loss: 0.2490 Generator Loss: 5.7306 \n",
            "Epoch:  26/200 Discriminator Loss: 0.2222 Generator Loss: 5.1023 \n",
            "Epoch:  27/200 Discriminator Loss: 0.1864 Generator Loss: 5.4150 \n",
            "Epoch:  28/200 Discriminator Loss: 0.1656 Generator Loss: 5.6517 \n",
            "Epoch:  29/200 Discriminator Loss: 0.1989 Generator Loss: 5.6731 \n",
            "Epoch:  30/200 Discriminator Loss: 0.1721 Generator Loss: 6.1821 \n",
            "Epoch:  31/200 Discriminator Loss: 0.2042 Generator Loss: 6.1403 \n",
            "Epoch:  32/200 Discriminator Loss: 0.2728 Generator Loss: 5.7698 \n",
            "Epoch:  33/200 Discriminator Loss: 0.7713 Generator Loss: 5.6576 \n",
            "Epoch:  34/200 Discriminator Loss: 0.2024 Generator Loss: 5.9319 \n",
            "Epoch:  35/200 Discriminator Loss: 0.2684 Generator Loss: 6.2158 \n",
            "Epoch:  36/200 Discriminator Loss: 0.2182 Generator Loss: 6.6039 \n",
            "Epoch:  37/200 Discriminator Loss: 0.2327 Generator Loss: 5.4045 \n",
            "Epoch:  38/200 Discriminator Loss: 0.2332 Generator Loss: 6.8096 \n",
            "Epoch:  39/200 Discriminator Loss: 0.2306 Generator Loss: 6.3126 \n",
            "Epoch:  40/200 Discriminator Loss: 0.2690 Generator Loss: 7.3549 \n",
            "Epoch:  41/200 Discriminator Loss: 0.2835 Generator Loss: 6.7341 \n",
            "Epoch:  42/200 Discriminator Loss: 0.2119 Generator Loss: 6.1777 \n",
            "Epoch:  43/200 Discriminator Loss: 0.3122 Generator Loss: 6.4219 \n",
            "Epoch:  44/200 Discriminator Loss: 0.2730 Generator Loss: 6.7493 \n",
            "Epoch:  45/200 Discriminator Loss: 1.3077 Generator Loss: 6.9506 \n",
            "Epoch:  46/200 Discriminator Loss: 0.1559 Generator Loss: 7.3172 \n",
            "Epoch:  47/200 Discriminator Loss: 0.1509 Generator Loss: 6.3853 \n",
            "Epoch:  48/200 Discriminator Loss: 0.1257 Generator Loss: 7.0231 \n",
            "Epoch:  49/200 Discriminator Loss: 0.1003 Generator Loss: 6.3520 \n",
            "Epoch:  50/200 Discriminator Loss: 0.1003 Generator Loss: 5.3336 \n",
            "Epoch:  51/200 Discriminator Loss: 0.0984 Generator Loss: 6.4881 \n",
            "Epoch:  52/200 Discriminator Loss: 0.1052 Generator Loss: 6.6338 \n",
            "Epoch:  53/200 Discriminator Loss: 0.1383 Generator Loss: 6.6399 \n",
            "Epoch:  54/200 Discriminator Loss: 0.3651 Generator Loss: 6.6588 \n",
            "Epoch:  55/200 Discriminator Loss: 0.1214 Generator Loss: 6.6954 \n",
            "Epoch:  56/200 Discriminator Loss: 0.1316 Generator Loss: 6.3700 \n",
            "Epoch:  57/200 Discriminator Loss: 0.1820 Generator Loss: 7.0390 \n",
            "Epoch:  58/200 Discriminator Loss: 0.1101 Generator Loss: 7.1981 \n",
            "Epoch:  59/200 Discriminator Loss: 0.1349 Generator Loss: 6.7237 \n",
            "Epoch:  60/200 Discriminator Loss: 0.1262 Generator Loss: 6.9229 \n",
            "Epoch:  61/200 Discriminator Loss: 0.1281 Generator Loss: 6.1271 \n",
            "Epoch:  62/200 Discriminator Loss: 0.1453 Generator Loss: 6.9230 \n",
            "Epoch:  63/200 Discriminator Loss: 0.1677 Generator Loss: 6.8267 \n",
            "Epoch:  64/200 Discriminator Loss: 1.3690 Generator Loss: 6.3826 \n",
            "Epoch:  65/200 Discriminator Loss: 0.1749 Generator Loss: 6.5979 \n",
            "Epoch:  66/200 Discriminator Loss: 1.7087 Generator Loss: 6.6629 \n",
            "Epoch:  67/200 Discriminator Loss: 0.1015 Generator Loss: 7.4160 \n",
            "Epoch:  68/200 Discriminator Loss: 0.1185 Generator Loss: 7.8831 \n",
            "Epoch:  69/200 Discriminator Loss: 0.1279 Generator Loss: 6.9601 \n",
            "Epoch:  70/200 Discriminator Loss: 0.1059 Generator Loss: 6.9238 \n",
            "Epoch:  71/200 Discriminator Loss: 0.1052 Generator Loss: 6.3999 \n",
            "Epoch:  72/200 Discriminator Loss: 0.1968 Generator Loss: 6.9767 \n",
            "Epoch:  73/200 Discriminator Loss: 0.1481 Generator Loss: 6.8163 \n",
            "Epoch:  74/200 Discriminator Loss: 0.1139 Generator Loss: 6.9393 \n",
            "Epoch:  75/200 Discriminator Loss: 0.1134 Generator Loss: 7.0818 \n",
            "Epoch:  76/200 Discriminator Loss: 0.1405 Generator Loss: 6.9816 \n",
            "Epoch:  77/200 Discriminator Loss: 0.1238 Generator Loss: 7.6879 \n",
            "Epoch:  78/200 Discriminator Loss: 0.1137 Generator Loss: 7.8401 \n",
            "Epoch:  79/200 Discriminator Loss: 0.1491 Generator Loss: 8.0746 \n",
            "Epoch:  80/200 Discriminator Loss: 0.1568 Generator Loss: 7.4066 \n",
            "Epoch:  81/200 Discriminator Loss: 0.1233 Generator Loss: 8.5912 \n",
            "Epoch:  82/200 Discriminator Loss: 0.0825 Generator Loss: 7.7005 \n",
            "Epoch:  83/200 Discriminator Loss: 0.1434 Generator Loss: 8.5692 \n",
            "Epoch:  84/200 Discriminator Loss: 0.1430 Generator Loss: 7.9627 \n",
            "Epoch:  85/200 Discriminator Loss: 0.1317 Generator Loss: 7.4641 \n",
            "Epoch:  86/200 Discriminator Loss: 0.1118 Generator Loss: 7.4118 \n",
            "Epoch:  87/200 Discriminator Loss: 0.1482 Generator Loss: 8.6133 \n",
            "Epoch:  88/200 Discriminator Loss: 0.1240 Generator Loss: 8.1514 \n",
            "Epoch:  89/200 Discriminator Loss: 0.1470 Generator Loss: 8.2093 \n",
            "Epoch:  90/200 Discriminator Loss: 0.1547 Generator Loss: 8.1409 \n",
            "Epoch:  91/200 Discriminator Loss: 0.1334 Generator Loss: 7.8468 \n",
            "Epoch:  92/200 Discriminator Loss: 0.2082 Generator Loss: 7.3112 \n",
            "Epoch:  93/200 Discriminator Loss: 0.1542 Generator Loss: 7.2959 \n",
            "Epoch:  94/200 Discriminator Loss: 0.0929 Generator Loss: 8.3866 \n",
            "Epoch:  95/200 Discriminator Loss: 0.1664 Generator Loss: 7.4249 \n",
            "Epoch:  96/200 Discriminator Loss: 0.1573 Generator Loss: 7.8480 \n",
            "Epoch:  97/200 Discriminator Loss: 0.1571 Generator Loss: 8.3142 \n",
            "Epoch:  98/200 Discriminator Loss: 0.0775 Generator Loss: 8.0617 \n",
            "Epoch:  99/200 Discriminator Loss: 0.1127 Generator Loss: 7.9271 \n",
            "Epoch: 100/200 Discriminator Loss: 0.7923 Generator Loss: 7.3978 \n",
            "Epoch: 101/200 Discriminator Loss: 0.0952 Generator Loss: 8.1577 \n",
            "Epoch: 102/200 Discriminator Loss: 0.1120 Generator Loss: 8.6916 \n",
            "Epoch: 103/200 Discriminator Loss: 0.1423 Generator Loss: 8.2849 \n",
            "Epoch: 104/200 Discriminator Loss: 0.0990 Generator Loss: 7.0681 \n",
            "Epoch: 105/200 Discriminator Loss: 0.3260 Generator Loss: 8.1108 \n",
            "Epoch: 106/200 Discriminator Loss: 0.3414 Generator Loss: 7.7757 \n",
            "Epoch: 107/200 Discriminator Loss: 0.1560 Generator Loss: 7.6796 \n",
            "Epoch: 108/200 Discriminator Loss: 0.1036 Generator Loss: 8.4220 \n",
            "Epoch: 109/200 Discriminator Loss: 0.1362 Generator Loss: 7.6855 \n",
            "Epoch: 110/200 Discriminator Loss: 0.1635 Generator Loss: 7.2234 \n",
            "Epoch: 111/200 Discriminator Loss: 0.1130 Generator Loss: 7.9148 \n",
            "Epoch: 112/200 Discriminator Loss: 0.6051 Generator Loss: 8.3477 \n",
            "Epoch: 113/200 Discriminator Loss: 0.1621 Generator Loss: 7.6600 \n",
            "Epoch: 114/200 Discriminator Loss: 0.1295 Generator Loss: 7.2073 \n",
            "Epoch: 115/200 Discriminator Loss: 0.1493 Generator Loss: 7.9436 \n",
            "Epoch: 116/200 Discriminator Loss: 0.2166 Generator Loss: 7.3108 \n",
            "Epoch: 117/200 Discriminator Loss: 0.3141 Generator Loss: 7.5946 \n",
            "Epoch: 118/200 Discriminator Loss: 0.2205 Generator Loss: 6.9453 \n",
            "Epoch: 119/200 Discriminator Loss: 0.2251 Generator Loss: 8.3716 \n",
            "Epoch: 120/200 Discriminator Loss: 0.1749 Generator Loss: 7.4293 \n",
            "Epoch: 121/200 Discriminator Loss: 0.2068 Generator Loss: 7.9201 \n",
            "Epoch: 122/200 Discriminator Loss: 0.1984 Generator Loss: 8.5659 \n",
            "Epoch: 123/200 Discriminator Loss: 0.1441 Generator Loss: 6.9771 \n",
            "Epoch: 124/200 Discriminator Loss: 0.1034 Generator Loss: 6.8556 \n",
            "Epoch: 125/200 Discriminator Loss: 0.0894 Generator Loss: 6.7251 \n",
            "Epoch: 126/200 Discriminator Loss: 0.1740 Generator Loss: 7.6621 \n",
            "Epoch: 127/200 Discriminator Loss: 0.1776 Generator Loss: 7.3326 \n",
            "Epoch: 128/200 Discriminator Loss: 0.1057 Generator Loss: 7.1649 \n",
            "Epoch: 129/200 Discriminator Loss: 0.1089 Generator Loss: 7.5105 \n",
            "Epoch: 130/200 Discriminator Loss: 0.1146 Generator Loss: 7.7928 \n",
            "Epoch: 131/200 Discriminator Loss: 0.1232 Generator Loss: 7.2704 \n",
            "Epoch: 132/200 Discriminator Loss: 0.1167 Generator Loss: 7.5747 \n",
            "Epoch: 133/200 Discriminator Loss: 0.1053 Generator Loss: 7.2498 \n",
            "Epoch: 134/200 Discriminator Loss: 0.0861 Generator Loss: 7.8104 \n",
            "Epoch: 135/200 Discriminator Loss: 0.1239 Generator Loss: 7.8508 \n",
            "Epoch: 136/200 Discriminator Loss: 0.4244 Generator Loss: 8.4064 \n",
            "Epoch: 137/200 Discriminator Loss: 0.1199 Generator Loss: 7.5421 \n",
            "Epoch: 138/200 Discriminator Loss: 0.1222 Generator Loss: 7.2000 \n",
            "Epoch: 139/200 Discriminator Loss: 0.1271 Generator Loss: 7.4232 \n",
            "Epoch: 140/200 Discriminator Loss: 0.1203 Generator Loss: 7.5042 \n",
            "Epoch: 141/200 Discriminator Loss: 0.0896 Generator Loss: 7.8204 \n",
            "Epoch: 142/200 Discriminator Loss: 0.1179 Generator Loss: 8.3213 \n",
            "Epoch: 143/200 Discriminator Loss: 0.0918 Generator Loss: 7.0126 \n",
            "Epoch: 144/200 Discriminator Loss: 0.0751 Generator Loss: 8.1873 \n",
            "Epoch: 145/200 Discriminator Loss: 0.1161 Generator Loss: 7.5879 \n",
            "Epoch: 146/200 Discriminator Loss: 0.1020 Generator Loss: 7.6284 \n",
            "Epoch: 147/200 Discriminator Loss: 0.1005 Generator Loss: 8.2478 \n",
            "Epoch: 148/200 Discriminator Loss: 0.0943 Generator Loss: 7.4608 \n",
            "Epoch: 149/200 Discriminator Loss: 0.1042 Generator Loss: 7.4890 \n",
            "Epoch: 150/200 Discriminator Loss: 0.1163 Generator Loss: 7.2796 \n",
            "Epoch: 151/200 Discriminator Loss: 0.0911 Generator Loss: 5.9334 \n",
            "Epoch: 152/200 Discriminator Loss: 0.1093 Generator Loss: 7.3499 \n",
            "Epoch: 153/200 Discriminator Loss: 0.1273 Generator Loss: 10.6505 \n",
            "Epoch: 154/200 Discriminator Loss: 0.4755 Generator Loss: 6.9671 \n",
            "Epoch: 155/200 Discriminator Loss: 0.1153 Generator Loss: 8.3904 \n",
            "Epoch: 156/200 Discriminator Loss: 0.0867 Generator Loss: 8.0253 \n",
            "Epoch: 157/200 Discriminator Loss: 0.0862 Generator Loss: 7.0528 \n",
            "Epoch: 158/200 Discriminator Loss: 0.1156 Generator Loss: 8.5983 \n",
            "Epoch: 159/200 Discriminator Loss: 0.0830 Generator Loss: 7.7396 \n",
            "Epoch: 160/200 Discriminator Loss: 0.0919 Generator Loss: 7.5258 \n",
            "Epoch: 161/200 Discriminator Loss: 0.0865 Generator Loss: 8.9425 \n",
            "Epoch: 162/200 Discriminator Loss: 0.1146 Generator Loss: 7.5283 \n",
            "Epoch: 163/200 Discriminator Loss: 0.1029 Generator Loss: 8.0920 \n",
            "Epoch: 164/200 Discriminator Loss: 0.1183 Generator Loss: 8.0341 \n",
            "Epoch: 165/200 Discriminator Loss: 0.1032 Generator Loss: 7.6384 \n",
            "Epoch: 166/200 Discriminator Loss: 0.1070 Generator Loss: 9.0830 \n",
            "Epoch: 167/200 Discriminator Loss: 0.0942 Generator Loss: 8.2031 \n",
            "Epoch: 168/200 Discriminator Loss: 0.1017 Generator Loss: 7.9660 \n",
            "Epoch: 169/200 Discriminator Loss: 0.0963 Generator Loss: 8.1704 \n",
            "Epoch: 170/200 Discriminator Loss: 0.0934 Generator Loss: 8.2406 \n",
            "Epoch: 171/200 Discriminator Loss: 0.0888 Generator Loss: 8.0449 \n",
            "Epoch: 172/200 Discriminator Loss: 0.1268 Generator Loss: 8.0882 \n",
            "Epoch: 173/200 Discriminator Loss: 0.1141 Generator Loss: 8.7627 \n",
            "Epoch: 174/200 Discriminator Loss: 0.1269 Generator Loss: 8.3261 \n",
            "Epoch: 175/200 Discriminator Loss: 0.1331 Generator Loss: 8.9436 \n",
            "Epoch: 176/200 Discriminator Loss: 0.1313 Generator Loss: 8.9888 \n",
            "Epoch: 177/200 Discriminator Loss: 0.0750 Generator Loss: 9.3446 \n",
            "Epoch: 178/200 Discriminator Loss: 0.1247 Generator Loss: 7.8254 \n",
            "Epoch: 179/200 Discriminator Loss: 0.0944 Generator Loss: 9.0276 \n",
            "Epoch: 180/200 Discriminator Loss: 0.1277 Generator Loss: 7.9187 \n",
            "Epoch: 181/200 Discriminator Loss: 0.1026 Generator Loss: 9.0825 \n",
            "Epoch: 182/200 Discriminator Loss: 0.0843 Generator Loss: 9.2967 \n",
            "Epoch: 183/200 Discriminator Loss: 0.1096 Generator Loss: 8.6336 \n",
            "Epoch: 184/200 Discriminator Loss: 0.1859 Generator Loss: 7.8649 \n",
            "Epoch: 185/200 Discriminator Loss: 0.0998 Generator Loss: 9.2692 \n",
            "Epoch: 186/200 Discriminator Loss: 0.3308 Generator Loss: 8.8594 \n",
            "Epoch: 187/200 Discriminator Loss: 0.0966 Generator Loss: 9.1850 \n",
            "Epoch: 188/200 Discriminator Loss: 0.1355 Generator Loss: 8.8114 \n",
            "Epoch: 189/200 Discriminator Loss: 0.1449 Generator Loss: 9.3916 \n",
            "Epoch: 190/200 Discriminator Loss: 0.1188 Generator Loss: 9.7200 \n",
            "Epoch: 191/200 Discriminator Loss: 0.1263 Generator Loss: 9.0377 \n",
            "Epoch: 192/200 Discriminator Loss: 0.1258 Generator Loss: 8.8780 \n",
            "Epoch: 193/200 Discriminator Loss: 0.4247 Generator Loss: 9.1008 \n",
            "Epoch: 194/200 Discriminator Loss: 0.1325 Generator Loss: 9.1505 \n",
            "Epoch: 195/200 Discriminator Loss: 0.1913 Generator Loss: 9.3023 \n",
            "Epoch: 196/200 Discriminator Loss: 0.2043 Generator Loss: 9.5052 \n",
            "Epoch: 197/200 Discriminator Loss: 0.2195 Generator Loss: 9.5718 \n",
            "Epoch: 198/200 Discriminator Loss: 0.1862 Generator Loss: 9.0358 \n",
            "Epoch: 199/200 Discriminator Loss: 0.1302 Generator Loss: 8.9390 \n",
            "Epoch: 200/200 Discriminator Loss: 0.1263 Generator Loss: 9.8078 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = np.array(losses)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.plot(losses.T[0], label='Discriminator')\n",
        "plt.plot(losses.T[1], label='Generator')\n",
        "plt.title(\"Training Losses\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "PggCTTOGDgna",
        "outputId": "5f0b56f7-2529-4403-ebb0-41d9680f32ae"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rr = discriminator.predict_on_batch(X_test_real)"
      ],
      "metadata": {
        "id": "YZIu_ZtmDhef"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "#import keras_metrics\n",
        "\n",
        "r = tf.keras.metrics.Recall()#thresholds=rr.min())\n",
        "r.update_state(y_test,rr )\n",
        "r.result().numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aiuPNLfDkQu",
        "outputId": "81f5c597-03d6-4c5a-de05-1276d99c70fb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.989899"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p=tf.keras.metrics.Precision()#thresholds=rr.min())\n",
        "p.update_state(y_test,rr )\n",
        "p.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lNCrQ-HDln4",
        "outputId": "a0eca19c-6580-4e61-d9ac-9a0b16a217d5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.989899"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}